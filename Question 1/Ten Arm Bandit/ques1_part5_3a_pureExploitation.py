import gym
import custom_bandits
import numpy as np
from gym import spaces
import matplotlib.pyplot as plt

def pureExploitation(env, maxEpisodes):
        Q = np.zeros(env.action_space.n)
        N = np.zeros(env.action_space.n)
        Q_est = np.zeros((maxEpisodes, env.action_space.n))
        a_history = np.zeros(maxEpisodes)
        r_history = np.zeros(maxEpisodes)
        regret_history = np.zeros(maxEpisodes)

        optimal_action = np.argmax(env.q_value)
        optimal_action_history = np.zeros(maxEpisodes)

        for i in range(maxEpisodes):
            env.reset()
            a = np.argmax(Q)
            _, R, _, _ = env.step(a)
            N[a] = N[a] + 1
            # print(N, a, R)
            Q[a] = Q[a] + (R-Q[a])/N[a]
            Q_est[i] = Q
            a_history[i] = a
            r_history[i] = R

            if i==0:
                regret_history[i] = env.q_value[optimal_action] - env.q_value[a]
            else:
                regret_history[i] = regret_history[i-1] + (env.q_value[optimal_action] - env.q_value[a])
            
            if a==optimal_action:
                optimal_action_history[i] = N[a]/(i+1)

        return Q_est, a_history, optimal_action_history, r_history, regret_history


if __name__ == "__main__":
    sigma = 1
    SEED = 0
    np.random.seed(SEED)
    maxEpisodes = 20
    env = gym.make('tenArmGaussian_bandits-v0', sigma_square=sigma, seed=SEED)
    env.reset()
    # print(env.q_value)
    # print(env.rewards)
    Q_estimates, action_history, optimal_action_history, reward_history, regret_history = pureExploitation(env,maxEpisodes)

    # print(Q_estimates[:,0].shape)
    # episodes = [i for i in range(maxEpisodes)]
    # plt.figure(figsize=(12,8))
    # plt.rcParams.update({'font.size': 14})
    # for i in range(env.action_space.n):
    #     plt.plot(episodes,Q_estimates[:,i], label='Q_est[a='+str(i)+']', linewidth=3)
    # plt.legend()
    # plt.show()
    print(f'--------------------SEED: {SEED}------------------------')
    print(f'True Q values: {env.q_value}')
    print(f'Final Q Estimates: {Q_estimates[-1,:]}')
    print(f'Action with highest q_value: {np.argmax(env.q_value)}')
    print(f'Q_val |Q[actionTaken]| actionTaken | reward')
    print('--------------------------------------------')
    for i in range(maxEpisodes-20, maxEpisodes):
        print(f'Q[{i}]| {Q_estimates[i][int(action_history[i])]:.2f} | action: {action_history[i]} | reward: {reward_history[i]}')